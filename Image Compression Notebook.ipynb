{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b473ad",
   "metadata": {},
   "source": [
    "# **CS105 Final Project (Team Number 7)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130781eb",
   "metadata": {},
   "source": [
    "#### **Group Members: Kush Momaya, Jeric Pascua, Sarah Armstrong, Pysey Ung, Eli Line-Im**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa33080f",
   "metadata": {},
   "source": [
    "## **Project Proposal - Image Compression**\n",
    "\n",
    "Our team project group proposal for the final project is about the compression of images through the K-means Clustering algorithm. K-means clustering is an algorithm in which objects are classified into different classes based on some sort of distance measure that is calculated between the objects. The clusters are then optimized through the reduction of their number or the change in their center. Image compression is the process of reducing the amount of space that an image takes through the reduction of unique colors. Additionally, the image must remain at a reasonable quality throughout the compression. We would like to explore the effectiveness of K-means Clustering across three different types of categories of images such as animals, buildings, and human faces. We would decide a number of clusters for each image and reduce that number until we see a significant decrease in the quality of the image. To optimize the number of clusters we would use the elbow method, where we plot the number of clusters, compared with a measure of variance to see which k would have the least impact on the reduction of quality. We would do this by using a for loop to calculate the SSE for a range of k-values for each image, and plotting the k-value and its related SSE. We would then compare the optimal k-value with what image appears to keep the important characteristics of the image. Furthermore, for each category, we would like to explore different images and discover the impact that changing the value of k has on each photo. From this, we can take the mean of k from each category, and compare the average k across all three categories. Our initial look at our data would be vectorizing the images and comparing their RGB values to see what kind of variance exists in the values for each image. We can then look at what this tells us about the k-values, both within categories and between categories. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10deb21",
   "metadata": {},
   "source": [
    "#### **Dataset:** https://drive.google.com/drive/folders/15OMJmn_gXL473LKGaDbD9ssrF8-GhgeA?usp=sharing\n",
    "\n",
    "Also located in original_images folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1662122",
   "metadata": {},
   "source": [
    "## **Contributions:**\n",
    "\n",
    "Kush Momaya: Used the K-means algorithm to compress and analyze 2 building images, constructed elbow graphs for each, performed EDA by vectorizing every image and plotting their respective bar charts. Performed data cleaning and preprocessing for the data by creating dataframes for each image to create visualizations. This involved analysis of color patterns when looking at EDA graphs and construction of initial hypotheses regarding the effects of image compression.\n",
    "\n",
    "Pysey Ung: Conducted K-means image compression on human face and building images, constructed elbow graphs for each, and analyzed the results of the different k-values and optimal cluster size. Retrieved images to add to the dataset.\n",
    "\n",
    "Sarah Armstrong: Used K-means clustering on human face images along with their respective elbow graphs and analyses, retrieved images to add to the dataset\n",
    "\n",
    "Jeric Pascua: K-Means image compression on nature and building images, exploratory data analysis using elbow graphs, and visual analysis comparing the results of each K-value effect on the original images, retrieved images to add to the dataset\n",
    "\n",
    "Eli Line-Im: Ran K mean algorithm on two nature images along with creating an elbow graph for each of the two nature images, as well as conducting their respective analysis. Retrieved images to add to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f920b5",
   "metadata": {},
   "source": [
    "## **Techniques:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9db9dc",
   "metadata": {},
   "source": [
    "We are using pandas and numpy for parts of our EDA and generating our elbow graphs so we can visualize our results and perform various calculations. Matplotlib helps with visualizing the data as well. The skimage library is what allows us to import and use the image in tandem with the sklearn library from which we import the k-means clustering algorithm. Finally we use the cv2 library to import images and vectorize them alongside pandas for the EDA part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2879156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae649074",
   "metadata": {},
   "source": [
    "## **Data Collection & Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc65be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing for Building Images\n",
    "nature1 = cv2.imread(\"../original_images/natureimage1.jpg\")\n",
    "nature1_rgb = cv2.cvtColor(nature1, cv2.COLOR_BGR2RGB)\n",
    "nature1_pixels = nature1_rgb.reshape(-1, 3)\n",
    "nature1_df = pd.DataFrame(nature1_pixels, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "nature2 = cv2.imread(\"../original_images/natureimage2.jpg\")\n",
    "nature2_rgb = cv2.cvtColor(nature2, cv2.COLOR_BGR2RGB)\n",
    "nature2_pixels = nature2_rgb.reshape(-1, 3)\n",
    "nature2_df = pd.DataFrame(nature2_pixels, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "nature3 = cv2.imread(\"../original_images/natureimage3.jpg\")\n",
    "nature3_rgb = cv2.cvtColor(nature3, cv2.COLOR_BGR2RGB)\n",
    "nature3_pixels = nature3_rgb.reshape(-1, 3)\n",
    "nature3_df = pd.DataFrame(nature3_pixels, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "initial_white_building = cv2.imread(\"../original_images/white_building.jpg\")\n",
    "white_building_rgb = cv2.cvtColor(initial_white_building, cv2.COLOR_BGR2RGB)\n",
    "white_building_pixels = white_building_rgb.reshape(-1, 3)\n",
    "white_building_df = pd.DataFrame(white_building_pixels, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "initial_brown_building = cv2.imread(\"../original_images/brown_building.jpg\")\n",
    "brown_building_rgb = cv2.cvtColor(initial_brown_building, cv2.COLOR_BGR2RGB)\n",
    "brown_building_pixels = brown_building_rgb.reshape(-1, 3)\n",
    "brown_building_df = pd.DataFrame(brown_building_pixels, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "initial_weird_building = cv2.imread(\"../original_images/weird_building.jpg\")\n",
    "weird_building_rgb = cv2.cvtColor(initial_weird_building, cv2.COLOR_BGR2RGB)\n",
    "weird_building_pixels = weird_building_rgb.reshape(-1, 3)\n",
    "weird_building_df = pd.DataFrame(weird_building_pixels, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "skyline = cv2.imread(\"../original_images/skyline.jpg\")\n",
    "skyline_rgb = cv2.cvtColor(skyline, cv2.COLOR_BGR2RGB)\n",
    "skyline_pixels = skyline_rgb.reshape(-1, 3)\n",
    "skyline_df = pd.DataFrame(skyline_pixels, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "teen_face = cv2.imread(\"../original_images/humanface1.jpg\")\n",
    "teen_face_rgb = cv2.cvtColor(teen_face, cv2.COLOR_BGR2RGB)\n",
    "teen_face_pixels = teen_face_rgb.reshape(-1, 3)\n",
    "teen_face_df = pd.DataFrame(teen_face_pixels, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "man_face = cv2.imread(\"../original_images/humanface2.jpg\")\n",
    "man_face_rgb = cv2.cvtColor(man_face, cv2.COLOR_BGR2RGB)\n",
    "man_face_pixels = man_face_rgb.reshape(-1, 3)\n",
    "man_face_df = pd.DataFrame(man_face_pixels, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "woman_face = cv2.imread(\"../original_images/women_face.jpg\")\n",
    "woman_face_rgb = cv2.cvtColor(woman_face, cv2.COLOR_BGR2RGB)\n",
    "woman_face_pixels = woman_face_rgb.reshape(-1, 3)\n",
    "woman_face_df = pd.DataFrame(woman_face_pixels, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "#brown_building_df\n",
    "#white_building_df\n",
    "#weird_building_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9ef5d",
   "metadata": {},
   "source": [
    "## **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11325c2",
   "metadata": {},
   "source": [
    "For our explatory data analysis we take the dataframes we made for each image and calculate the median for each RGB column. We then plot them against each other to compare the variance in the color pixel values. We are looking to see if there is a relation between the variance in pixel color values and the optimal k-value observed, both between the different categories and within the individual images. These bar charts help us visualize which images have significant variances and which ones seem to have an uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728af63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nature1_median_values = nature1_df[['R', 'G', 'B']].median()\n",
    "plt.bar(nature1_median_values.index, nature1_median_values.values)\n",
    "plt.ylabel('Median')\n",
    "plt.title('Median Values for the First Nature Image')\n",
    "plt.show()\n",
    "\n",
    "nature2_median_values = nature2_df[['R', 'G', 'B']].median()\n",
    "plt.bar(nature2_median_values.index, nature2_median_values.values)\n",
    "plt.ylabel('Median')\n",
    "plt.title('Median Values for the Second Nature Image')\n",
    "plt.show()\n",
    "\n",
    "nature3_median_values = nature3_df[['R', 'G', 'B']].median()\n",
    "plt.bar(nature3_median_values.index, nature3_median_values.values)\n",
    "plt.ylabel('Median')\n",
    "plt.title('Median Values for the Third Nature Image')\n",
    "plt.show()\n",
    "\n",
    "brown_median_values = brown_building_df[['R', 'G', 'B']].median()\n",
    "plt.bar(brown_median_values.index, brown_median_values.values)\n",
    "plt.ylabel('Median')\n",
    "plt.title('Median Values for the Brown Building')\n",
    "plt.show()\n",
    "\n",
    "white_median_values = white_building_df[['R', 'G', 'B']].median()\n",
    "plt.bar(white_median_values.index, white_median_values.values)\n",
    "plt.ylabel('Median')\n",
    "plt.title('Median Values for the White Building')\n",
    "plt.show()\n",
    "\n",
    "weird_median_values = weird_building_df[['R', 'G', 'B']].median()\n",
    "plt.bar(weird_median_values.index, weird_median_values.values)\n",
    "plt.ylabel('Median')\n",
    "plt.title('Median Values for the Geometric Building')\n",
    "plt.show()\n",
    "\n",
    "skyline_median_values = skyline_df[['R', 'G', 'B']].median()\n",
    "plt.bar(skyline_median_values.index, skyline_median_values.values)\n",
    "plt.ylabel('Median')\n",
    "plt.title('Median Values for the LA Skyline')\n",
    "plt.show()\n",
    "\n",
    "teen_median_values = teen_face_df[['R', 'G', 'B']].median()\n",
    "plt.bar(teen_median_values.index, teen_median_values.values)\n",
    "plt.ylabel('Median')\n",
    "plt.title('Median Values for the Teenager Face')\n",
    "plt.show()\n",
    "\n",
    "man_median_values = man_face_df[['R', 'G', 'B']].median()\n",
    "plt.bar(man_median_values.index, man_median_values.values)\n",
    "plt.ylabel('Median')\n",
    "plt.title('Median Values for the Man Face')\n",
    "plt.show()\n",
    "\n",
    "woman_median_values = woman_face_df[['R', 'G', 'B']].median()\n",
    "plt.bar(woman_median_values.index, woman_median_values.values)\n",
    "plt.ylabel('Median')\n",
    "plt.title('Median Values for the Woman Face')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de6308",
   "metadata": {},
   "source": [
    "## **K-Means Clustering Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b76bf66",
   "metadata": {},
   "source": [
    "This is where we conducting our analysis, by running the k-means clustering algorithm on each image. We did this by reading in the image, reshaping them to fit into the algorithm, and then running it. We do this by calling the algorithm with the desired number of iterations and the k-value, fitting it to the image, and then reclustering it with new center and compressing them. We talk about the reason we chose these numbers for k and iterations depending on what image we are analyzing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567ea3c",
   "metadata": {},
   "source": [
    "### Nature Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29ca90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = io.imread('natureimage1.jpg')\n",
    "io.imshow(image)\n",
    "io.show()\n",
    "rows = image.shape[0]\n",
    "cols = image.shape[1]\n",
    "image = image.reshape(rows*cols, 3)\n",
    "\n",
    "print(\"k=64\")\n",
    "kmeans = KMeans(n_clusters= 64, n_init= 4)\n",
    "kmeans.fit(image)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_64.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "print(\"k=32\")\n",
    "kmeans = KMeans(n_clusters= 32, n_init= 10)\n",
    "kmeans.fit(image)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_64.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "print(\"k=16\")\n",
    "kmeans = KMeans(n_clusters= 16, n_init= 10)\n",
    "kmeans.fit(image)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_64.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "print(\"k=8\")\n",
    "kmeans = KMeans(n_clusters= 8, n_init= 10)\n",
    "kmeans.fit(image)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_64.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "print(\"k=4\")\n",
    "kmeans = KMeans(n_clusters= 4, n_init= 10)\n",
    "kmeans.fit(image)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_64.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05107929",
   "metadata": {},
   "source": [
    "After running the K-mean Algorithm on the first nature image, we can see that the best max K value was 64 because the compressed image is extremely identical to the original image. However, the compressed image is still acceptable at k = 16 because the compressed image still has equal variability in color as the original image. Yet, this does not hold true for k = 8 because we can see that the variability in color is no longer the same as the flowers no longer have a reddish pinkish color. Furthermore, as k gets smaller which can be seen at k = 4, the image is no acceptable in terms of the color when comparing itself to the original image because when k does equal 4 like in one of the compressed images above, there seems to be no difference in colors between the types of flowers, and along with the sun and mountains. Even though this is the case, the image is still acceptable at k = 4 because even though there is a loss of color contrast between the details, the shapes and the placements of the objects within the image do not differ from the original image. Thus, the smallest value k can be to output an acceptable compressed image is 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da31c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = []\n",
    "\n",
    "k_values = range(1,11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters = k, n_init = 4)\n",
    "    kmeans.fit(image)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "    \n",
    "plt.plot(k_values, SSE, marker='o')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Graph')\n",
    "plt.xticks(k_values) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3499a4",
   "metadata": {},
   "source": [
    "After visualizing the clusters across the SSE for the first nature image, we can see that by the Elbow Method the best acceptable number of clusters for k is 3. The number of clusters determined by the the K-mean algorithm method was higher than the number of clusters determined by the elbow method by 1. Thus, the number of clusters determined to be acceptable by both method are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd532be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = io.imread('natureimage2.jpg')\n",
    "io.imshow(image)\n",
    "io.show()\n",
    "rows = image.shape[0]\n",
    "cols = image.shape[1]\n",
    "image = image.reshape(rows*cols, 3)\n",
    "\n",
    "print(\"k=64\")\n",
    "kmeans = KMeans(n_clusters= 64, n_init= 10)\n",
    "kmeans.fit(image)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_64.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "\n",
    "print(\"k=32\")\n",
    "kmeans = KMeans(n_clusters= 32, n_init= 10)\n",
    "kmeans.fit(image)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_64.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "print(\"k=16\")\n",
    "kmeans = KMeans(n_clusters= 16, n_init= 10)\n",
    "kmeans.fit(image)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_64.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "print(\"k=8\")\n",
    "kmeans = KMeans(n_clusters= 8, n_init= 10)\n",
    "kmeans.fit(image)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_64.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "print(\"k=4\")\n",
    "kmeans = KMeans(n_clusters= 4, n_init= 10)\n",
    "kmeans.fit(image)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_64.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e4798",
   "metadata": {},
   "source": [
    "After running the K-mean Algorithm on the second nature image, we can see that the best max K value was 64 because the compressed image is extremely identical to the original image. However, the compressed image is still acceptable at k = 16 because the compressed image still has equal variability in color as the original image. Yet, this does not hold true for k = 8 because we can see that the variability in color is no longer the same as the color of the moss on the rocks is no longer distinguishable from the color of the pine trees in the background. Furthermore, as k gets smaller which can be seen at k = 4, the image no longer acceptable in terms of the color because there is no differentiation in color between the rocks, trees, moss, and parts of the mountain. Furthermore, parts of the mountain seems to be the same color as the sky, but this is the case because in the original image, the color of the higher parts of the mountain are a mixture of green and blue. Thus, the smallest value k can be to output an acceptable compressed image is 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = []\n",
    "\n",
    "k_values = range(1,11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters = k, n_init = 4)\n",
    "    kmeans.fit(image)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "    \n",
    "plt.plot(k_values, SSE, marker='o')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Graph')\n",
    "plt.xticks(k_values) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb71dc7",
   "metadata": {},
   "source": [
    "After visualizing the clusters across the SSE for the second nature image, we can see that by the Elbow Method the best acceptable number of clusters for k is 3. The number of clusters determined by the the K-mean algorithm method was higher than the number of clusters determined by the elbow method by 1. Thus, the number of clusters determined to be acceptable by both method are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7863e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread('natureimage3.jpg') #<- insert image path\n",
    "image = image / 255.0\n",
    "rows, cols, channels = image.shape\n",
    "natimage_2d = image.reshape(rows * cols, channels)\n",
    "io.imshow(natimage_2d)\n",
    "#Perform K-means clustering\n",
    "\n",
    "print(\"k=64\")\n",
    "k_clusters = 64\n",
    "kmeans = KMeans(n_clusters=k_clusters, n_init = 3)\n",
    "kmeans.fit(natimage_2d)\n",
    "labels = kmeans.predict(natimage_2d)\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "compressed_image_2d = cluster_centers[labels]\n",
    "compressed_image = compressed_image_2d.reshape(rows, cols, channels)\n",
    "\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "print(\"k=16\")\n",
    "k_clusters = 16\n",
    "kmeans = KMeans(n_clusters=k_clusters, n_init = 3)\n",
    "kmeans.fit(natimage_2d)\n",
    "labels = kmeans.predict(natimage_2d)\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "compressed_image_2d = cluster_centers[labels]\n",
    "compressed_image = compressed_image_2d.reshape(rows, cols, channels)\n",
    "\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "print(\"k=4\")\n",
    "k_clusters = 4\n",
    "kmeans = KMeans(n_clusters=k_clusters, n_init = 3)\n",
    "kmeans.fit(natimage_2d)\n",
    "labels = kmeans.predict(natimage_2d)\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "compressed_image_2d = cluster_centers[labels]\n",
    "compressed_image = compressed_image_2d.reshape(rows, cols, channels)\n",
    "\n",
    "io.imshow(compressed_image)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b56b9cd",
   "metadata": {},
   "source": [
    "For images of nature and landscapes, a higher K-value results in a compressed image that for the most part stays true to the original image quality. For a K-value between 16 amd 64, the compressed image retains image quality and color tone of the original with the main difference being the clarity, or definition, of the original but that is to be expected when running image compression. The details of the original image remains intact as you can distinguish the petals of an individual flower in the field and the shadows amongst the trees or the gradient in the sky. A lower K-value, such as 4, results in a huge loss in image quality as it becomes more difficult to distinguish any of the small details of the original. The photo is still identifiable as the shape of the photo is still prevalent as it is still clear that we are looking at a field in the woods but it is hard to tell what type it is. In addition, the color tone of the original photo is completey lost. Additionally, when running the algorithm with a lower number of iterations its still able to produce an optimally compressed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5773aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = []\n",
    "\n",
    "k_values = range(1,11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters = k, n_init = 4)\n",
    "    kmeans.fit(natimage_2d)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "    \n",
    "plt.plot(k_values, SSE, marker='o')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Graph')\n",
    "plt.xticks(k_values) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48995d9",
   "metadata": {},
   "source": [
    "### Building Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b25b15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = io.imread('white_building.jpg')\n",
    "io.imshow(image)\n",
    "io.show()\n",
    "rows = image.shape[0]\n",
    "cols = image.shape[1]\n",
    "image = image.reshape(rows*cols, 3)\n",
    "\n",
    "\n",
    "print(\"k=64\")\n",
    "kmeans = KMeans(n_clusters=64, n_init = 2)\n",
    "kmeans.fit(image)\n",
    "compressed_image64 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image64 = compressed_image64.reshape(rows, cols, 3)\n",
    "compressed_image64 = np.clip(compressed_image64.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_64.png', compressed_image16)\n",
    "io.imshow(compressed_image64)\n",
    "io.show()\n",
    "\n",
    "print(\"k=32\")\n",
    "kmeans = KMeans(n_clusters=32, n_init = 2)\n",
    "kmeans.fit(image)\n",
    "compressed_image32 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image32 = compressed_image32.reshape(rows, cols, 3)\n",
    "compressed_image32 = np.clip(compressed_image32.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_32.png', compressed_image16)\n",
    "io.imshow(compressed_image32)\n",
    "io.show()\n",
    "\n",
    "print(\"k=16\")\n",
    "kmeans = KMeans(n_clusters=16, n_init = 2)\n",
    "kmeans.fit(image)\n",
    "compressed_image16 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image16 = compressed_image16.reshape(rows, cols, 3)\n",
    "compressed_image16 = np.clip(compressed_image16.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_16.png', compressed_image16)\n",
    "io.imshow(compressed_image16)\n",
    "io.show()\n",
    "\n",
    "print(\"k=8\")\n",
    "kmeans = KMeans(n_clusters=8, n_init = 2)\n",
    "kmeans.fit(image)\n",
    "compressed_image8 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image8 = compressed_image8.reshape(rows, cols, 3)\n",
    "compressed_image8 = np.clip(compressed_image8.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_8.png', compressed_image8)\n",
    "io.imshow(compressed_image8)\n",
    "io.show()\n",
    "\n",
    "print(\"k=4\")\n",
    "kmeans = KMeans(n_clusters=4, n_init = 2)\n",
    "kmeans.fit(image)\n",
    "compressed_image4 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image4 = compressed_image4.reshape(rows, cols, 3)\n",
    "compressed_image4 = np.clip(compressed_image4.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_4.png', compressed_image4)\n",
    "io.imshow(compressed_image4)\n",
    "io.show()\n",
    "\n",
    "print(\"k=2\")\n",
    "kmeans = KMeans(n_clusters=2, n_init = 2)\n",
    "kmeans.fit(image)\n",
    "compressed_image2 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image2 = compressed_image2.reshape(rows, cols, 3)\n",
    "compressed_image2 = np.clip(compressed_image2.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_4.png', compressed_image2)\n",
    "io.imshow(compressed_image2)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689fb14",
   "metadata": {},
   "source": [
    "Looking at the image of this building we see that the major drop in color detail happens when you cluster the image with a k-value of 16 versus a k-value of 8. With a k-value of 16 we still see some amount of color detail present in the grass and the sky but when you drop down to 8 the entire image becomes grayscale while still maintaining the adequate amount of detail necessary for someone to be able to make out the important aspects of the image such as the distinct floors of the building, the individual window panels and the buildings in the background. Dropping down to a k-value of 4 makes the image become very grainy with the sky becoming less saturated but the important aspects of the photo are still largely visible. At a final k-value of 2, the image crosses the threshold of acceptable quality as a large amount of the detail is lost and the shapes in the image become amorphous. Therefore we see that a k-value of 4 seems to achieve the optimal compression. The reason we chose 2 iterations for this image is because of the distribution of the RGB values. Looking back at the earlier distribution for RGB values within this image we do not see a lot of variation between the different colors and on a first look at the image we see a lot of uniformity so it is not necessary to run a larger number of iterations on this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c13d03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SSE = []\n",
    "\n",
    "k_values = range(1, 11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init = 4)\n",
    "    kmeans.fit(image)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.plot(k_values, SSE, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Chart')\n",
    "plt.xticks(k_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da10c76",
   "metadata": {},
   "source": [
    "To decide the optimimum amount of clusters for this algorithm we used the elbow method to compare the Sum of Squared Errors within each cluster for the number of clusters. Looking at this graph we see that the reduction in variance evens out around 3 or 4 clusters. For this image we chose to go with 4 clusters because there are not that many unique colors present within the image so there is no need to have more clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a1aef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = io.imread('brown_building.jpg')\n",
    "io.imshow(image)\n",
    "io.show()\n",
    "rows = image.shape[0]\n",
    "cols = image.shape[1]\n",
    "image = image.reshape(rows*cols, 3)\n",
    "\n",
    "\n",
    "print(\"k=64\")\n",
    "kmeans = KMeans(n_clusters=64, n_init = 4)\n",
    "kmeans.fit(image)\n",
    "compressed_image64 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image64 = compressed_image64.reshape(rows, cols, 3)\n",
    "compressed_image64 = np.clip(compressed_image64.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_64.png', compressed_image8)\n",
    "io.imshow(compressed_image64)\n",
    "io.show()\n",
    "\n",
    "print(\"k=32\")\n",
    "kmeans = KMeans(n_clusters=32, n_init = 4)\n",
    "kmeans.fit(image)\n",
    "compressed_image32 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image32 = compressed_image32.reshape(rows, cols, 3)\n",
    "compressed_image32 = np.clip(compressed_image32.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_32.png', compressed_image16)\n",
    "io.imshow(compressed_image32)\n",
    "io.show()\n",
    "\n",
    "print(\"k=16\")\n",
    "kmeans = KMeans(n_clusters=16, n_init = 4)\n",
    "kmeans.fit(image)\n",
    "compressed_image16 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image16 = compressed_image16.reshape(rows, cols, 3)\n",
    "compressed_image16 = np.clip(compressed_image16.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_16.png', compressed_image16)\n",
    "io.imshow(compressed_image16)\n",
    "io.show()\n",
    "\n",
    "print(\"k=8\")\n",
    "kmeans = KMeans(n_clusters=8, n_init = 4)\n",
    "kmeans.fit(image)\n",
    "compressed_image8 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image8 = compressed_image8.reshape(rows, cols, 3)\n",
    "compressed_image8 = np.clip(compressed_image8.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_8.png', compressed_image8)\n",
    "io.imshow(compressed_image8)\n",
    "io.show()\n",
    "\n",
    "print(\"k=4\")\n",
    "kmeans = KMeans(n_clusters=4, n_init = 4)\n",
    "kmeans.fit(image)\n",
    "compressed_image4 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image4 = compressed_image4.reshape(rows, cols, 3)\n",
    "compressed_image4 = np.clip(compressed_image4.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_4.png', compressed_image4)\n",
    "io.imshow(compressed_image4)\n",
    "io.show()\n",
    "\n",
    "print(\"k=2\")\n",
    "kmeans = KMeans(n_clusters=2, n_init = 4)\n",
    "kmeans.fit(image)\n",
    "compressed_image2 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image2 = compressed_image2.reshape(rows, cols, 3)\n",
    "compressed_image2 = np.clip(compressed_image2.astype('uint8'), 0, 255)\n",
    "#io.imsave('compressed_image_4.png', compressed_image2)\n",
    "io.imshow(compressed_image2)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55679002",
   "metadata": {},
   "source": [
    "This image contained a larger variety of colors when compared to the first one but they are clumped in a similar way. The compression with a k-value of 16, seems to just desaturate the image with a darker shade of brown and a little less detail with the smaller parts like the car and trees. We also notice the tree colors begin to take on the color of the building because the colors are overlapped in the image. Dropping down to a k-value of 8 we see pretty much the same results as the previous compression, with what appears to be a desaturation of the colors and a little more of a grainy appearance on the buildings. Dropping to 4 however sees the largest change yet with the smaller details on the building going away and a lot of the colors also fading away but the details still remain. Dropping to two however completely rids the image of its original color characteritics, showing that a k-value of four seems to be the ideal k for this image. We chose four iterations for this image because it has overlapping colors with the car and the tree in the bottom and a higher presence of colors in general so it is necessary for more iterations to properly sort the cluster centers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecde170",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SSE = []\n",
    "\n",
    "k_values = range(1, 11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init = 4)\n",
    "    kmeans.fit(image)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.plot(k_values, SSE, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Chart')\n",
    "plt.xticks(k_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c75cfa",
   "metadata": {},
   "source": [
    "As we see through this elbow chart the optimal number of clusters seems to be four. We see that there is a noticeable difference in the amount of variance between 3 and 4 clusters, unlike the previous image where there was not a large difference between 3 and 4 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeefb257",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "building3_image = io.imread('weird_building.jpg')\n",
    "io.imshow(building3_image)\n",
    "io.show()\n",
    "\n",
    "\n",
    "#Flatten the image\n",
    "rows = building3_image.shape[0]\n",
    "cols = building3_image.shape[1]\n",
    "\n",
    "building3_image = building3_image.reshape(rows * cols, 3)\n",
    "\n",
    "\n",
    "#Initialize kmean for k = 64\n",
    "print(\"k=64\")\n",
    "kmeans = KMeans(n_clusters = 64, n_init = 4)\n",
    "kmeans.fit(building3_image)\n",
    "compressed_building3 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_building3 = np.clip(compressed_building3.astype('uint8'), 0, 255)\n",
    "compressed_building3 = compressed_building3.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_building3_64.png', compressed_building3)\n",
    "io.imshow(compressed_building3)\n",
    "io.show()\n",
    "\n",
    "#Initialize kmean for k = 32\n",
    "print(\"k=32\")\n",
    "kmeans = KMeans(n_clusters = 32, n_init = 4)\n",
    "kmeans.fit(building3_image)\n",
    "compressed_building3 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_building3 = np.clip(compressed_building3.astype('uint8'), 0, 255)\n",
    "compressed_building3 = compressed_building3.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_building3_32.png', compressed_building3)\n",
    "io.imshow(compressed_building3)\n",
    "io.show()\n",
    "\n",
    "#Initialize kmean for k = 16\n",
    "print(\"k=16\")\n",
    "kmeans = KMeans(n_clusters = 16, n_init = 4)\n",
    "kmeans.fit(building3_image)\n",
    "compressed_building3 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_building3 = np.clip(compressed_building3.astype('uint8'), 0, 255)\n",
    "compressed_building3 = compressed_building3.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_building3_16.png', compressed_building3)\n",
    "io.imshow(compressed_building3)\n",
    "io.show()\n",
    "\n",
    "#Initialize kmean for k = 4\n",
    "print(\"k=4\")\n",
    "kmeans = KMeans(n_clusters = 4, n_init = 4)\n",
    "kmeans.fit(building3_image)\n",
    "compressed_building3 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_building3 = np.clip(compressed_building3.astype('uint8'), 0, 255)\n",
    "compressed_building3 = compressed_building3.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_building3_4.png', compressed_building3)\n",
    "io.imshow(compressed_building3)\n",
    "io.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a5270",
   "metadata": {},
   "source": [
    "With a k-value  64 we see very insignificant changes with the only noticeable difference in the layers of colors in the sky. At a k of 32 we begin to see the smoothing of some surfaces on the building and the sky begins to be defined into a few very visibly different categories but there is still an acceptable amount of detail available in the image. Dropping to 16 shows the same pattern of changes that dropping to 32 did, with the sky becoming 6 separate colors but the building retaining majority of a color detail. At 4 however, we see the colors all become distorted with the blue associated with the sky applied to parts of the building and the building loses majority of its orginal characteristics. Similarly to the previous building, we use four iterations because is a larger difference in the colors which was reflected in the distribution of its RGB values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = []\n",
    "\n",
    "k_values = range(1, 11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init = 4)\n",
    "    kmeans.fit(building3_image)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.plot(k_values, SSE, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Chart')\n",
    "plt.xticks(k_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and preprocess the image\n",
    "image = io.imread('skyline.jpg') #<- insert image path\n",
    "image = image / 255.0\n",
    "rows, cols, channels = image.shape\n",
    "laimage_2d = image.reshape(rows * cols, channels)\n",
    "\n",
    "#Perform K-means clustering\n",
    "print(\"k=64\")\n",
    "k_clusters = 64\n",
    "kmeans = KMeans(n_clusters=k_clusters, n_init = 4)\n",
    "kmeans.fit(laimage_2d)\n",
    "labels = kmeans.predict(laimage_2d)\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "compressed_image_2d = cluster_centers[labels]\n",
    "compressed_image = compressed_image_2d.reshape(rows, cols, channels)\n",
    "\n",
    "#Save the compressed image\n",
    "#io.imsave('./Compressed/LAskyline/compressed_LAskyline_k_64.jpg', compressed_image) #<- insert image destination\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "print(\"k=16\")\n",
    "k_clusters = 16\n",
    "kmeans = KMeans(n_clusters=k_clusters, n_init = 4)\n",
    "kmeans.fit(laimage_2d)\n",
    "labels = kmeans.predict(laimage_2d)\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "compressed_image_2d = cluster_centers[labels]\n",
    "compressed_image = compressed_image_2d.reshape(rows, cols, channels)\n",
    "\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "print(\"k=4\")\n",
    "k_clusters = 4\n",
    "kmeans = KMeans(n_clusters=k_clusters, n_init = 4)\n",
    "kmeans.fit(laimage_2d)\n",
    "labels = kmeans.predict(laimage_2d)\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "compressed_image_2d = cluster_centers[labels]\n",
    "compressed_image = compressed_image_2d.reshape(rows, cols, channels)\n",
    "\n",
    "io.imshow(compressed_image)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f89f32",
   "metadata": {},
   "source": [
    "When applying K-means clustering to images of buildings, specifically a city skyline, a higher K-value will produce an image that stays true to the original tone of the image before compression and ensures that the image quality is retained. For example using a K-value equal to 16 or 64, the image quality and color tone of the original image is retained after compression. In addition, for both K-values of 16 and 64 the details of the original photo remain intact as we can visibly notice little things such as the windows and antennas on a building or the gradient in the sky. The only thing lost after compression is the clarity/definition of the image but that is expected with this process. When a lower K-value is selected the shape of the original image remains intact but thats the only quality that remains from the original photo. The image quality and overall color tone of the original photo is lost in the process and only the dominate colors remain. Certain details remain in both skyline photos but in general a majority of the little details in the buildings are lost as well as the gradient in the sky for both is lost as it essentially becomes monotone. Overall, using a lower K-value results in a very grainy image with a lack of color but is still identifiable as it is still clear that the compressed images are of city skylines. Also to note, when running this algorithm with a small number of iteration it still produces an optimally compressed image for all values of K tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = []\n",
    "\n",
    "k_values = range(1, 11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init = 4)\n",
    "    kmeans.fit(laimage_2d)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.plot(k_values, SSE, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Chart')\n",
    "plt.xticks(k_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037ba6f",
   "metadata": {},
   "source": [
    "### Human Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee6a7cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "teen_image = io.imread('humanface1.jpg')\n",
    "io.imshow(teen_image)\n",
    "io.show()\n",
    "#Dimension of the original image\n",
    "rows = teen_image.shape[0]\n",
    "cols = teen_image.shape[1]\n",
    "#Flatten the image\n",
    "teen_image = teen_image.reshape(rows*cols, 3)\n",
    "\n",
    "\n",
    "#Implement k-means clustering to form k clusters\n",
    "\n",
    "print(\"k=32\")\n",
    "kmeans = KMeans(n_clusters=32, n_init = 3)\n",
    "kmeans.fit(teen_image)\n",
    "compressed_image32 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image32 = np.clip(compressed_image32.astype('uint8'), 0, 255)\n",
    "compressed_image32 = compressed_image32.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_32.png', compressed_image32)\n",
    "io.imshow(compressed_image32)\n",
    "io.show()\n",
    "\n",
    "print(\"k=16\")\n",
    "kmeans = KMeans(n_clusters=16, n_init = 3)\n",
    "kmeans.fit(teen_image)\n",
    "compressed_image16 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image16 = np.clip(compressed_image16.astype('uint8'), 0, 255)\n",
    "compressed_image16 = compressed_image16.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_16.png', compressed_image16)\n",
    "io.imshow(compressed_image16)\n",
    "io.show()\n",
    "\n",
    "print(\"k=4\")\n",
    "kmeans = KMeans(n_clusters=4, n_init = 3)\n",
    "kmeans.fit(teen_image)\n",
    "compressed_image4 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image4 = np.clip(compressed_image4.astype('uint8'), 0, 255)\n",
    "compressed_image4 = compressed_image4.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_4.png', compressed_image4)\n",
    "io.imshow(compressed_image4)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f04572",
   "metadata": {},
   "source": [
    "Overall, the quality of the image decreases as the k-value decreases, but the level of acceptable quality of the image is mostly not lost. For k-value 32, the image is extremely similar to the original, with changes to color not being too noticeable. For k-value 16, a loss of detail starts to become noticeable, although the image still shows some detail. For k-value 8, the loss of detail is much more noticeable with the face losing depth and appearing flat. However, the main details and contours are mostly preserved. For k-value 4, the image changes to grayscale. The main shape of the face is still shown, but the left ear starts to blend into the background, indicating if k decreases even more, the image may be indistinguishable. Since the image does not vary a lot in color, K-Means clustering doesn't require a high number of iterations to compress the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SSE = []\n",
    "\n",
    "k_values = range(1, 8)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init = 2)\n",
    "    kmeans.fit(teen_image)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.plot(k_values, SSE, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Chart')\n",
    "plt.xticks(k_values)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec16e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "man_image = io.imread('humanface2.jpg')\n",
    "io.imshow(man_image)\n",
    "io.show()\n",
    "#Dimension of the original image\n",
    "rows = man_image.shape[0]\n",
    "cols = man_image.shape[1]\n",
    "#Flatten the image\n",
    "man_image = man_image.reshape(rows*cols, 3)\n",
    "\n",
    "\n",
    "#Implement k-means clustering to form k clusters\n",
    "\n",
    "print(\"k=16\")\n",
    "kmeans = KMeans(n_clusters=16, n_init = 3)\n",
    "kmeans.fit(man_image)\n",
    "compressed_image16 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image16 = np.clip(compressed_image16.astype('uint8'), 0, 255)\n",
    "compressed_image16 = compressed_image16.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_16.png', compressed_image16)\n",
    "io.imshow(compressed_image16)\n",
    "io.show()\n",
    "\n",
    "print(\"k=4\")\n",
    "kmeans = KMeans(n_clusters=4, n_init = 3)\n",
    "kmeans.fit(man_image)\n",
    "compressed_image4 = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image4 = np.clip(compressed_image4.astype('uint8'), 0, 255)\n",
    "compressed_image4 = compressed_image4.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_4.png', compressed_image4)\n",
    "io.imshow(compressed_image4)\n",
    "io.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3e160",
   "metadata": {},
   "source": [
    "Similar to the first image, the quality of this image decreases as the k-value decreases, but the level of acceptable quality of the image is mostly not lost. For k-value 16, the compressed image is extremely similar to the original. The face becomes slightly fuzzier and pixels become a little more noticeable. For k-value 4, the image becomes grayscale, with the man's shirt starting to blend into the background. Since the main features of the image are not lost, k-value 4 appears to be the minimum k-value to compress this image and retain image quality. Since the image does not vary a lot in color, K-Means clustering doesn't require a high number of iterations to compress the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = []\n",
    "\n",
    "k_values = range(1, 11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init = 4)\n",
    "    kmeans.fit(man_image)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.plot(k_values, SSE, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Chart')\n",
    "plt.xticks(k_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdac2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image3 = io.imread('women_face.jpg')\n",
    "io.imshow(image3)\n",
    "io.show()\n",
    "#print(image3.shape)\n",
    "labels = plt.axes(xticks=[], yticks=[])\n",
    "labels.imshow(image3);\n",
    "#Flatten the image\n",
    "rows = image3.shape[0]\n",
    "cols = image3.shape[1]\n",
    "image3 = image3.reshape(rows * cols, 3)\n",
    "\n",
    "\n",
    "#Initialized kmean for k = 64\n",
    "print(\"k=64\")\n",
    "kmeans = KMeans(n_clusters = 64, n_init = 2)\n",
    "kmeans.fit(image3)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_64.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "#Initialize kmean for k = 32\n",
    "print(\"k=32\")\n",
    "kmeans = KMeans(n_clusters = 32, n_init = 2)\n",
    "kmeans.fit(image3)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_32.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "#Initialize kmean for k = 16\n",
    "print(\"k=16\")\n",
    "kmeans = KMeans(n_clusters = 16, n_init = 2)\n",
    "kmeans.fit(image3)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_16.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "#Initialize kmean for k = 4\n",
    "print(\"k=4\")\n",
    "kmeans = KMeans(n_clusters = 4, n_init = 2)\n",
    "kmeans.fit(image3)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_4.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()\n",
    "\n",
    "#Initialize kmean for k = 2\n",
    "print(\"k=2\")\n",
    "kmeans = KMeans(n_clusters = 2, n_init = 2)\n",
    "kmeans.fit(image3)\n",
    "compressed_image = kmeans.cluster_centers_[kmeans.labels_]\n",
    "compressed_image = np.clip(compressed_image.astype('uint8'), 0, 255)\n",
    "compressed_image = compressed_image.reshape(rows, cols, 3)\n",
    "io.imsave('compressed_image_2.png', compressed_image)\n",
    "io.imshow(compressed_image)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fa4be",
   "metadata": {},
   "source": [
    "For this image we see no noticeable drop in quality at a k of 64. An important characteristic of this image is that the color of the woman's t-shirt is very similar to the background. Her face begins to desaturate at k=32 and this continues until k=16, but at k=4 we see the t-shirt completely blend into the background but the outlines of her face and features still remain. K=4 therefore shows a minimum acceptable level of detail but k=16 seems to meet a better balance of optimization and detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3cf688",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = []\n",
    "\n",
    "k_values = range(1, 11)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, n_init = 4)\n",
    "    kmeans.fit(image3)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "plt.plot(k_values, SSE, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('Elbow Chart')\n",
    "plt.xticks(k_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc647fab",
   "metadata": {},
   "source": [
    "## **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417ad0d",
   "metadata": {},
   "source": [
    "Now that we have all of the results of the compressions we can calculate the optimal k for each category by finding the mean of the images within them. For the nature images we find that the algorithm provided an optimal mean of 4, for the buildings it said 3.75 and for the human faces it said 3.3334. Looking at the categories separately we notice that the nature image values seem to contain a larger variety of colors when compared to the other categories which is what can contribute to the increased mean when. Examining the bar charts we made during our EDA process, we see that in every chart for the nature images, there is a clear variance in the RGB values which we said would be a predicting value for the optimal number of clusters given by the elbow graphs. Looking at the bar charts for the building images we see a smaller amount of variance when compared to the nature images, but there still exists some variance in all but the white building. This is again correlated with the higher mean optimal number of clusters when compared to the human faces category. That category had the least amount of variance in the initial RGB bar charts, and this was reflected by it having the lowest mean number of clusters, by a larger margin than the difference between the nature and building images, which places an emphasis on the uniformity of the colors and its relationship with the number of optimal clusters found by the k-means algorithm. Looking at the individual images we found that for the more colorful images, although the algorithm suggested a smaller k value for the best compression, we preferred a larger k-value so that the colors were preserved. At k-values like four, the overall shape of the images was kept and the significant parts of the images were still distinct, but a large portion of the color detail was absent. For the human faces and building photos this was not as much of a problem, but for the nature photos they began to appear as desaturated blobs and since there were large clumps of colors, they lost a large portion of the detail required to distinguish certain parts of the image. From this we can conclude that as we saw a larger variety in the colors of the image, both we and the algorithm preferred a larger k-value, with our eyes preferring significant increases and the algorithm preferring more minor increases in the number of clusters. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
